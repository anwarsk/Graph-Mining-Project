{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PUAdapter(object):\n",
    "    \"\"\"\n",
    "    Adapts any probabilistic binary classifier to positive-unlabled learning using the PosOnly method proposed by\n",
    "    Elkan and Noto:\n",
    "\n",
    "    Elkan, Charles, and Keith Noto. \\\"Learning classifiers from only positive and unlabeled data.\\\"\n",
    "    Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2008.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, estimator, hold_out_ratio=0.1, precomputed_kernel=False):\n",
    "        \"\"\"\n",
    "        estimator -- An estimator of p(s=1|x) that must implement:\n",
    "                     * predict_proba(X): Takes X, which can be a list of feature vectors or a precomputed\n",
    "                                         kernel matrix and outputs p(s=1|x) for each example in X\n",
    "                     * fit(X,y): Takes X, which can be a list of feature vectors or a precomputed\n",
    "                                 kernel matrix and takes y, which are the labels associated to the\n",
    "                                 examples in X\n",
    "        hold_out_ratio -- The ratio of training examples that must be held out of the training set of examples\n",
    "                          to estimate p(s=1|y=1) after training the estimator\n",
    "        precomputed_kernel -- Specifies if the X matrix for predict_proba and fit is a precomputed kernel matrix\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.c = 1.0\n",
    "        self.hold_out_ratio = hold_out_ratio\n",
    "        \n",
    "        if precomputed_kernel:\n",
    "            self.fit = self.__fit_precomputed_kernel\n",
    "        else:\n",
    "            self.fit = self.__fit_no_precomputed_kernel\n",
    "\n",
    "        self.estimator_fitted = False\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'Estimator:' + str(self.estimator) + '\\n' + 'p(s=1|y=1,x) ~= ' + str(self.c) + '\\n' + \\\n",
    "            'Fitted: ' + str(self.estimator_fitted)\n",
    "    \n",
    "    \n",
    "    def __fit_precomputed_kernel(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits an estimator of p(s=1|x) and estimates the value of p(s=1|y=1) using a subset of the training examples\n",
    "        X -- Precomputed kernel matrix\n",
    "        y -- Labels associated to each example in X (Positive label: 1.0, Negative label: -1.0)\n",
    "        \"\"\"\n",
    "        positives = np.where(y == 1.)[0]\n",
    "        hold_out_size = np.ceil(len(positives) * self.hold_out_ratio)\n",
    "\n",
    "        if len(positives) <= hold_out_size:\n",
    "            raise('Not enough positive examples to estimate p(s=1|y=1,x). Need at least ' + str(hold_out_size + 1) + '.')\n",
    "        \n",
    "        np.random.shuffle(positives)\n",
    "        hold_out = positives[:hold_out_size]\n",
    "        \n",
    "        #Hold out test kernel matrix\n",
    "        X_test_hold_out = X[hold_out]\n",
    "        keep = list(set(np.arange(len(y))) - set(hold_out))\n",
    "        X_test_hold_out = X_test_hold_out[:,keep]\n",
    "        \n",
    "        #New training kernel matrix\n",
    "        X = X[:, keep]\n",
    "        X = X[keep]\n",
    "\n",
    "        y = np.delete(y, hold_out)\n",
    "        \n",
    "        self.estimator.fit(X, y)\n",
    "        \n",
    "        hold_out_predictions = self.estimator.predict_proba(X_test_hold_out)\n",
    "        \n",
    "        try:\n",
    "            hold_out_predictions = hold_out_predictions[:,1]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        c = np.mean(hold_out_predictions)\n",
    "        self.c = c\n",
    "        \n",
    "        self.estimator_fitted = True\n",
    "        \n",
    "        \n",
    "    def __fit_no_precomputed_kernel(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits an estimator of p(s=1|x) and estimates the value of p(s=1|y=1,x)\n",
    "\n",
    "        X -- List of feature vectors\n",
    "        y -- Labels associated to each feature vector in X (Positive label: 1.0, Negative label: -1.0)\n",
    "        \"\"\"\n",
    "        positives = np.where(y == 1.)[0]\n",
    "        hold_out_size = int(np.ceil(len(positives) * self.hold_out_ratio))\n",
    "\n",
    "        if len(positives) <= hold_out_size:\n",
    "            raise('Not enough positive examples to estimate p(s=1|y=1,x). Need at least ' + str(hold_out_size + 1) + '.')\n",
    "        \n",
    "        np.random.shuffle(positives)\n",
    "        print(len(positives))\n",
    "        print(hold_out_size)\n",
    "        hold_out = positives[:hold_out_size]\n",
    "        print(max(hold_out))\n",
    "        print(len(X))\n",
    "        X_hold_out = X[hold_out]\n",
    "        X = np.delete(X, hold_out,0)\n",
    "        \n",
    "        y_hold_out = y[hold_out]\n",
    "        y = np.delete(y, hold_out)\n",
    "        \n",
    "        self.estimator.fit(X, y)\n",
    "        \n",
    "        hold_out_predictions = self.estimator.predict(X_hold_out)\n",
    "        \n",
    "        try:\n",
    "            hold_out_predictions = hold_out_predictions[:,1]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        c = np.mean(hold_out_predictions)\n",
    "        self.c = c\n",
    "        \n",
    "        print(\"### HOLD OUT PREDICTIONS\")\n",
    "        print(hold_out_predictions)\n",
    "        class_hold_out_prediction = hold_out_predictions\n",
    "        #class_hold_out_prediction[class_hold_out_prediction> 0.5] = 1\n",
    "        #class_hold_out_prediction[class_hold_out_prediction< 0.5] = -1\n",
    "        \n",
    "        #print(len(hold_out_predictions[hold_out_predictions < 0.5]))\n",
    "        #print(class_hold_out_prediction)\n",
    "        print(\"## YHOLDOUT\")\n",
    "        print(y_hold_out)\n",
    "        \n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.metrics import precision_score\n",
    "        from sklearn.metrics import classification_report\n",
    "        print(classification_report(y_hold_out, class_hold_out_prediction))\n",
    "        print(confusion_matrix(y_hold_out, class_hold_out_prediction))\n",
    "        \n",
    "        self.estimator_fitted = True\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predicts p(y=1|x) using the estimator and the value of p(s=1|y=1) estimated in fit(...)\n",
    "\n",
    "        X -- List of feature vectors or a precomputed kernel matrix\n",
    "        \"\"\"\n",
    "        if not self.estimator_fitted:\n",
    "            raise Exception('The estimator must be fitted before calling predict_proba(...).')\n",
    "\n",
    "        probabilistic_predictions = self.estimator.predict_proba(X)\n",
    "        \n",
    "        try:\n",
    "            probabilistic_predictions = probabilistic_predictions[:,1]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return probabilistic_predictions / self.c\n",
    "    \n",
    "    \n",
    "    def predict(self, X, treshold=0.5):\n",
    "        \"\"\"\n",
    "        Assign labels to feature vectors based on the estimator's predictions\n",
    "\n",
    "        X -- List of feature vectors or a precomputed kernel matrix\n",
    "        treshold -- The decision treshold between the positive and the negative class\n",
    "        \"\"\"\n",
    "        if not self.estimator_fitted:\n",
    "            raise Exception('The estimator must be fitted before calling predict(...).')\n",
    "\n",
    "        return np.array([1. if p > treshold else -1. for p in self.predict_proba(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_positive = positive_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unlabled = unlabled_cases.sample(8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_unlabled.append(X_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.Cited.replace(0,-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X['Cited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop(['Cited', 'AuthorId', 'ArticleId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaBoost = AdaBoostClassifier(n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_estimator = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pu_estimator = PUAdapter(adaBoost, hold_out_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_estimator.fit(X.as_matrix(),y.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pu_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_values = pu_estimator.predict(unlabled_cases.drop(['Cited', 'AuthorId', 'ArticleId'], axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_class = unlabled_cases.Cited.replace(0,-1)\n",
    "print(classification_report(true_class, predicted_values))\n",
    "print(confusion_matrix(true_class, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of estimator and PUAdapter(estimator):\")\n",
    "print(\"Number of disagreements: \", len(np.where((pu_estimator.predict(X) == nb_estimator.predict(X)) == False)[0]))\n",
    "print(\"Number of agreements: \", len(np.where((pu_estimator.predict(X) == nb_estimator.predict(X)) == True)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[[12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unlabled = unlabled_cases.drop('Cited', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PU-Learning using Naive Bayes and EM\n",
    "Two Step Method\n",
    "(1) Find the reliable negative documents from the data\n",
    "(2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_bernouli = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_val_score(NB_bernouli, X, y, cv=5, scoring='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AuthorId                 0\n",
       "ArticleId                0\n",
       "ShortestDistance         0\n",
       "RandomWalkProbability    0\n",
       "CurrentScoringMethod     0\n",
       "PathLength=1             0\n",
       "PathLength=2             0\n",
       "PathLength=3             0\n",
       "PathLength=4             0\n",
       "Cited                    0\n",
       "N2VAvgCosDist            0\n",
       "D2VAvgCosDist            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = pd.read_csv('/Users/anwar/java_workspace/Graph-Mining-Project/output/graph_features_max_depth_4/feature_vector_complete.csv')\n",
    "\n",
    "input_data = input_data.fillna(np.mean(input_data['D2VAvgCosDist']))\n",
    "\n",
    "input_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>ShortestDistance</th>\n",
       "      <th>RandomWalkProbability</th>\n",
       "      <th>CurrentScoringMethod</th>\n",
       "      <th>PathLength=1</th>\n",
       "      <th>PathLength=2</th>\n",
       "      <th>PathLength=3</th>\n",
       "      <th>PathLength=4</th>\n",
       "      <th>Cited</th>\n",
       "      <th>N2VAvgCosDist</th>\n",
       "      <th>D2VAvgCosDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_71187</td>\n",
       "      <td>571857</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>2676</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386456</td>\n",
       "      <td>0.295523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a_71187</td>\n",
       "      <td>571835</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350226</td>\n",
       "      <td>0.303250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a_71187</td>\n",
       "      <td>571856</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448654</td>\n",
       "      <td>0.269440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a_71187</td>\n",
       "      <td>571834</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449872</td>\n",
       "      <td>0.343334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_71187</td>\n",
       "      <td>571877</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444690</td>\n",
       "      <td>0.264319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AuthorId  ArticleId  ShortestDistance  RandomWalkProbability  \\\n",
       "0  a_71187     571857                 2               0.032341   \n",
       "1  a_71187     571835                 4               0.000303   \n",
       "2  a_71187     571856                 4               0.000861   \n",
       "3  a_71187     571834                 4               0.000224   \n",
       "4  a_71187     571877                -1               0.000000   \n",
       "\n",
       "   CurrentScoringMethod  PathLength=1  PathLength=2  PathLength=3  \\\n",
       "0              0.009708             0             5            81   \n",
       "1              0.000076             0             0             0   \n",
       "2              0.000215             0             0             0   \n",
       "3              0.000056             0             0             0   \n",
       "4              0.000000             0             0             0   \n",
       "\n",
       "   PathLength=4  Cited  N2VAvgCosDist  D2VAvgCosDist  \n",
       "0          2676    1.0       0.386456       0.295523  \n",
       "1            26    0.0       0.350226       0.303250  \n",
       "2            87    0.0       0.448654       0.269440  \n",
       "3             7    0.0       0.449872       0.343334  \n",
       "4             0    0.0       0.444690       0.264319  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cases = input_data[input_data['Cited'] == 1]\n",
    "\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3893, 12)"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cases.head()\n",
    "positive_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabled_cases = input_data[input_data['Cited'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159994, 12)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabled_cases.head()\n",
    "unlabled_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShortestDistance</th>\n",
       "      <th>RandomWalkProbability</th>\n",
       "      <th>CurrentScoringMethod</th>\n",
       "      <th>PathLength=1</th>\n",
       "      <th>PathLength=2</th>\n",
       "      <th>PathLength=3</th>\n",
       "      <th>PathLength=4</th>\n",
       "      <th>N2VAvgCosDist</th>\n",
       "      <th>D2VAvgCosDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>2676</td>\n",
       "      <td>0.386456</td>\n",
       "      <td>0.295523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.044821</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.355503</td>\n",
       "      <td>0.268981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>0.278734</td>\n",
       "      <td>0.163345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>356</td>\n",
       "      <td>0.443134</td>\n",
       "      <td>0.298214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "      <td>1518</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.298214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShortestDistance  RandomWalkProbability  CurrentScoringMethod  \\\n",
       "0                 2               0.032341              0.009708   \n",
       "1                 2               0.044821              0.015211   \n",
       "2                 2               0.003465              0.001258   \n",
       "3                 2               0.001315              0.000453   \n",
       "4                 2               0.009318              0.003383   \n",
       "\n",
       "   PathLength=1  PathLength=2  PathLength=3  PathLength=4  N2VAvgCosDist  \\\n",
       "0             0             5            81          2676       0.386456   \n",
       "1             0            11            84          2001       0.355503   \n",
       "2             0             1             2            97       0.278734   \n",
       "3             0             1            17           356       0.443134   \n",
       "4             0             5            61          1518       0.433034   \n",
       "\n",
       "   D2VAvgCosDist  \n",
       "0       0.295523  \n",
       "1       0.268981  \n",
       "2       0.163345  \n",
       "3       0.298214  \n",
       "4       0.298214  "
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = positive_cases.reset_index(drop=True)\n",
    "P_hold_out = P.sample(frac=0.15)\n",
    "P = P.drop(P_hold_out.index)\n",
    "P.head()\n",
    "P_hold_out.head()\n",
    "\n",
    "U = unlabled_cases.reset_index(drop=True)\n",
    "U.Cited.replace(0,-1, inplace = True)\n",
    "U_hold_out = U.sample(frac=0.025)\n",
    "U = U.drop(U_hold_out.index)\n",
    "U.head()\n",
    "U_hold_out.head()\n",
    "\n",
    "X_input = P.append(U)\n",
    "X_input = X_input.reset_index(drop= True)\n",
    "y_input = X_input['Cited']\n",
    "X_input = X_input.drop(['Cited', 'AuthorId', 'ArticleId'], axis=1)\n",
    "X_input.ShortestDistance.replace(-1, 9999, inplace=True)\n",
    "X_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = adb_classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97153007  0.02846993]\n",
      " [ 0.97153007  0.02846993]\n",
      " [ 0.97153007  0.02846993]\n",
      " ..., \n",
      " [ 0.97518052  0.02481948]\n",
      " [ 0.97828708  0.02171292]\n",
      " [ 0.97654459  0.02345541]]\n",
      "[     0      1      2 ..., 155991 155992 155993]\n",
      "Number of RN-  147988\n",
      "[[  2.22044605e-16   1.00000000e+00]\n",
      " [  2.22044605e-16   1.00000000e+00]\n",
      " [  2.22044605e-16   1.00000000e+00]\n",
      " ..., \n",
      " [  2.22044605e-16   1.00000000e+00]\n",
      " [  2.22044605e-16   1.00000000e+00]\n",
      " [  2.22044605e-16   1.00000000e+00]]\n",
      "[]\n",
      "Number of RN-  0\n",
      "NO RN Found\n"
     ]
    }
   ],
   "source": [
    "isConverged = False\n",
    "U_Input = U.reset_index(drop=True)\n",
    "U_Input.ShortestDistance.replace(-1, 9999)\n",
    "RN = U_Input\n",
    "RN_threshold = 0.95\n",
    "iterationCount = 0\n",
    "while(not isConverged):\n",
    "    X_input = P.append(RN)\n",
    "    X_input = X_input.reset_index(drop= True)\n",
    "    y_input = X_input['Cited']\n",
    "    X_input = X_input.drop(['Cited', 'AuthorId', 'ArticleId'], axis=1)\n",
    "    X_input.ShortestDistance.replace(-1, 9999, inplace=True)\n",
    "    #print(y_input)\n",
    "    classifier.fit(X_input, y_input)\n",
    "    U_Input = U_Input.reset_index(drop=True)\n",
    "    U_probabilities = classifier.predict_proba(U_Input.drop(['Cited', 'AuthorId', 'ArticleId'], axis=1))\n",
    "    print(U_probabilities)\n",
    "    RN_index = np.where(U_probabilities[:,0]>RN_threshold)[0]\n",
    "    print(RN_index)\n",
    "    RN = U_Input.iloc[RN_index,:]\n",
    "    U_Input = U_Input.drop(RN_index)\n",
    "    print(\"Number of RN- \", len(RN))\n",
    "    iterationCount+=1\n",
    "    RN_threshold *= 0.9\n",
    "    if(len(RN) <1):\n",
    "        isConverged = True\n",
    "        print(\"NO RN Found\")\n",
    "    if(iterationCount >30):\n",
    "        isConverged = True\n",
    "        print(\"Max Iteration Count Reached\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = P_hold_out.append(U_hold_out)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "Y_test = X_test['Cited']\n",
    "X_test = X_test.drop(['Cited', 'AuthorId', 'ArticleId'],  axis =1)\n",
    "\n",
    "Y_test_predict = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3800,  200],\n",
       "       [   0,  584]])"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(Y_test, Y_test_predict,labels=[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-363-15ce8af85e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultinomialNB' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "nb_classifier.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = U_Input.iloc[[2,5,7],:]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB(fit_prior=False)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb_classfier = AdaBoostClassifier(n_estimators=10)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc_classifier = SVC()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=6)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn_clf = MLPClassifier(hidden_layer_sizes=(20,20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U_probabilities1 = np.array([[1,2],[3,4],[5,6]])\n",
    "U_probabilities1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b= np.where(U_probabilities1>5)[0]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U_probabilities[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(U_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.export_graphviz(dt_clf, out_file='/Users/anwar/jupyter_workspace/tree1.dot')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dot_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-350-9d4c04a62757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/anwar/jupyter_workspace/graph.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/anwar/anaconda/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mgraph_from_dot_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdot_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dot_parser' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "import pydot \n",
    "\n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(dt_clf, out_file=dot_data) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"/Users/anwar/jupyter_workspace/graph.pdf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
